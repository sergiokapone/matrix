import pandas as pd
import yaml
from pathlib import Path

def csv_to_yaml_mappings(csv_file, yaml_template_file=None, output_file=None):
    """
    –ö–æ–Ω–≤–µ—Ä—Ç—É—î CSV —Ñ–∞–π–ª —É YAML mappings

    CSV —Ñ–æ—Ä–º–∞—Ç:
    –®–∏—Ñ—Ä | –ù–∞–∑–≤–∞ –¥–∏—Å—Ü–∏–ø–ª—ñ–Ω–∏ | –ö–æ–º–ø–µ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—ñ | –†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –Ω–∞–≤—á–∞–Ω–Ω—è
    –ó–û 01 | –ú–∞—Ç–µ–º–∞—Ç–∏—á–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ | –ó–ö 1, –ó–ö 2, –§–ö 6 | –ü–†–ù 1, –ü–†–ù 2
    """

    try:
        # –ß–∏—Ç–∞—î–º–æ CSV
        df = pd.read_csv(csv_file, encoding='utf-8')

        # –û—á–∏—â—É—î–º–æ –∑–∞–≥–æ–ª–æ–≤–∫–∏ –≤—ñ–¥ –∑–∞–π–≤–∏—Ö –ø—Ä–æ–±—ñ–ª—ñ–≤
        df.columns = df.columns.str.strip()

        # –ú–æ–∂–ª–∏–≤—ñ –≤–∞—Ä—ñ–∞–Ω—Ç–∏ –Ω–∞–∑–≤ –∫–æ–ª–æ–Ω–æ–∫
        code_col = find_column(df, ['—à–∏—Ñ—Ä', '–∫–æ–¥', 'code', '—à–∏—Ñ—Ä –¥–∏—Å—Ü–∏–ø–ª—ñ–Ω–∏'])
        name_col = find_column(df, ['–Ω–∞–∑–≤–∞', '–¥–∏—Å—Ü–∏–ø–ª—ñ–Ω–∞', '–Ω–∞–∑–≤–∞ –¥–∏—Å—Ü–∏–ø–ª—ñ–Ω–∏', 'name', 'discipline'])
        comp_col = find_column(df, ['–∫–æ–º–ø–µ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—ñ', '–∫–æ–º–ø–µ—Ç–µ–Ω—Ü—ñ—ó', 'competencies'])
        prn_col = find_column(df, ['—Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏', '–ø—Ä–æ–≥—Ä–∞–º–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏', '–ø—Ä–Ω', 'program_results', 'results'])

        if not all([code_col, name_col, comp_col, prn_col]):
            missing = []
            if not code_col: missing.append("–®–∏—Ñ—Ä/–ö–æ–¥")
            if not name_col: missing.append("–ù–∞–∑–≤–∞ –¥–∏—Å—Ü–∏–ø–ª—ñ–Ω–∏")
            if not comp_col: missing.append("–ö–æ–º–ø–µ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—ñ")
            if not prn_col: missing.append("–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –Ω–∞–≤—á–∞–Ω–Ω—è")

            print(f"‚ùå –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∫–æ–ª–æ–Ω–∫–∏: {', '.join(missing)}")
            print(f"üìã –î–æ—Å—Ç—É–ø–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏: {', '.join(df.columns.tolist())}")
            return False

        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ —ñ—Å–Ω—É—é—á–∏–π YAML —à–∞–±–ª–æ–Ω –∞–±–æ —Å—Ç–≤–æ—Ä—é—î–º–æ –±–∞–∑–æ–≤–∏–π
        if yaml_template_file and Path(yaml_template_file).exists():
            with open(yaml_template_file, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            print(f"üìÇ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ —à–∞–±–ª–æ–Ω: {yaml_template_file}")
        else:
            config = create_basic_yaml_structure()
            print("üìù –°—Ç–≤–æ—Ä–µ–Ω–æ –±–∞–∑–æ–≤—É YAML —Å—Ç—Ä—É–∫—Ç—É—Ä—É")

        # –ü–∞—Ä—Å–∏–º–æ CSV —Ç–∞ —Å—Ç–≤–æ—Ä—é—î–º–æ mappings
        mappings = {}
        disciplines_from_csv = {}
        errors = []

        for index, row in df.iterrows():
            try:
                # –û—Ç—Ä–∏–º—É—î–º–æ –¥–∞–Ω—ñ –∑ —Ä—è–¥–∫–∞
                code = str(row[code_col]).strip()
                name = str(row[name_col]).strip()
                competencies_str = str(row[comp_col]).strip() if pd.notna(row[comp_col]) else ""
                results_str = str(row[prn_col]).strip() if pd.notna(row[prn_col]) else ""

                if not code or code == 'nan':
                    continue

                # –ü–∞—Ä—Å–∏–º–æ –∫–æ–º–ø–µ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—ñ
                competencies = parse_items_list(competencies_str)
                program_results = parse_items_list(results_str)

                # –î–æ–¥–∞—î–º–æ –¥–æ mappings
                if competencies or program_results:
                    mappings[code] = {
                        "competencies": competencies,
                        "program_results": program_results
                    }

                # –î–æ–¥–∞—î–º–æ –¥–∏—Å—Ü–∏–ø–ª—ñ–Ω—É
                if name and name != 'nan':
                    disciplines_from_csv[code] = name

            except Exception as e:
                errors.append(f"–†—è–¥–æ–∫ {index + 2}: {str(e)}")

        # –û–Ω–æ–≤–ª—é—î–º–æ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—é
        config["mappings"] = mappings

        # –î–æ–¥–∞—î–º–æ –Ω–æ–≤—ñ –¥–∏—Å—Ü–∏–ø–ª—ñ–Ω–∏ (—è–∫—â–æ —ó—Ö –Ω–µ–º–∞—î —É —à–∞–±–ª–æ–Ω—ñ)
        if "disciplines" not in config:
            config["disciplines"] = {}

        for code, name in disciplines_from_csv.items():
            if code not in config["disciplines"]:
                config["disciplines"][code] = name

        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if not output_file:
            output_file = Path(csv_file).with_suffix('.yaml')

        with open(output_file, 'w', encoding='utf-8') as f:
            yaml.dump(config, f, allow_unicode=True, default_flow_style=False,
                     indent=2, sort_keys=False)

        # –ó–≤—ñ—Ç
        print(f"‚úÖ –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {output_file}")
        print(f"üìä –û–±—Ä–æ–±–ª–µ–Ω–æ –¥–∏—Å—Ü–∏–ø–ª—ñ–Ω: {len(mappings)}")
        print(f"üìä –î–æ–¥–∞–Ω–æ –Ω–æ–≤–∏—Ö –¥–∏—Å—Ü–∏–ø–ª—ñ–Ω: {len(disciplines_from_csv)}")

        if errors:
            print(f"\n‚ö†Ô∏è –ü–æ–º–∏–ª–∫–∏ ({len(errors)}):")
            for error in errors[:5]:  # –ü–æ–∫–∞–∑—É—î–º–æ –ø–µ—Ä—à—ñ 5 –ø–æ–º–∏–ª–æ–∫
                print(f"  ‚Ä¢ {error}")
            if len(errors) > 5:
                print(f"  ... —Ç–∞ —â–µ {len(errors) - 5} –ø–æ–º–∏–ª–æ–∫")

        return True

    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —á–∏—Ç–∞–Ω–Ω—è CSV: {e}")
        return False

def find_column(df, possible_names):
    """–ó–Ω–∞—Ö–æ–¥–∏—Ç—å –∫–æ–ª–æ–Ω–∫—É –∑–∞ –º–æ–∂–ª–∏–≤–∏–º–∏ –Ω–∞–∑–≤–∞–º–∏"""
    df_cols_lower = [col.lower().strip() for col in df.columns]

    for name in possible_names:
        name_lower = name.lower().strip()
        if name_lower in df_cols_lower:
            return df.columns[df_cols_lower.index(name_lower)]

    # –ü–æ—à—É–∫ –ø–æ —á–∞—Å—Ç–∫–æ–≤–æ–º—É –∑–±—ñ–≥—É
    for name in possible_names:
        name_lower = name.lower().strip()
        for i, col in enumerate(df_cols_lower):
            if name_lower in col or col in name_lower:
                return df.columns[i]

    return None

def parse_items_list(items_str):
    """
    –ü–∞—Ä—Å–∏—Ç—å —Ä—è–¥–æ–∫ –∑ –ø–µ—Ä–µ–ª—ñ–∫–æ–º –∫–æ–¥—ñ–≤
    –ü—Ä–∏–∫–ª–∞–¥: "–ó–ö 1, –ó–ö 2, –§–ö 6" ‚Üí ["–ó–ö 1", "–ó–ö 2", "–§–ö 6"]
    """
    if not items_str or items_str == 'nan':
        return []

    # –†–æ–∑–¥—ñ–ª—è—î–º–æ –ø–æ –∫–æ–º–∞—Ö, –∫—Ä–∞–ø—Ü—ñ –∑ –∫–æ–º–æ—é, –∞–±–æ –ø–µ—Ä–µ–Ω–æ—Å—É —Ä—è–¥–∫–∞
    items = []
    raw_items = items_str.replace(';', ',').replace('\n', ',').split(',')

    for item in raw_items:
        item = item.strip()
        if item and item != '-' and item.lower() != '–Ω–µ–º–∞—î':
            # –ù–æ—Ä–º–∞–ª—ñ–∑—É—î–º–æ —Ñ–æ—Ä–º–∞—Ç (–¥–æ–¥–∞—î–º–æ –ø—Ä–æ–±—ñ–ª –º—ñ–∂ –ª—ñ—Ç–µ—Ä–∞–º–∏ —ñ —Ü–∏—Ñ—Ä–∞–º–∏)
            import re
            item = re.sub(r'([–ê-–Ø]+)(\d+)', r'\1 \2', item)
            items.append(item)

    return items

def create_basic_yaml_structure():
    """–°—Ç–≤–æ—Ä—é—î –±–∞–∑–æ–≤—É YAML —Å—Ç—Ä—É–∫—Ç—É—Ä—É"""
    return {
        "metadata": {
            "title": "–û—Å–≤—ñ—Ç–Ω—å–æ-–ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–∞ –ø—Ä–æ–≥—Ä–∞–º–∞ (–∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ –∑ CSV)",
            "university": "–ù–∞—Ü—ñ–æ–Ω–∞–ª—å–Ω–∏–π —Ç–µ—Ö–Ω—ñ—á–Ω–∏–π —É–Ω—ñ–≤–µ—Ä—Å–∏—Ç–µ—Ç –£–∫—Ä–∞—ó–Ω–∏ \"–ö–ü–Ü —ñ–º. –Ü–≥–æ—Ä—è –°—ñ–∫–æ—Ä—Å—å–∫–æ–≥–æ\"",
            "faculty": "–ù–ù –§—ñ–∑–∏–∫–æ-—Ç–µ—Ö–Ω—ñ—á–Ω–∏–π —ñ–Ω—Å—Ç–∏—Ç—É—Ç",
            "department": "–ö–∞—Ñ–µ–¥—Ä–∞ –ø—Ä–∏–∫–ª–∞–¥–Ω–æ—ó —Ñ—ñ–∑–∏–∫–∏", 
            "specialty": "105 –ü—Ä–∏–∫–ª–∞–¥–Ω–∞ —Ñ—ñ–∑–∏–∫–∞",
            "website": "https://osvita.kpi.ua",
            "year": "2024",
            "degree": "–ë–∞–∫–∞–ª–∞–≤—Ä",
            "created_date": pd.Timestamp.now().strftime("%Y-%m-%d"),
            "last_updated": pd.Timestamp.now().strftime("%Y-%m-%d"),
            "credits_total": 240,

        },
        "disciplines": {},
        "competencies": {},
        "program_results": {},
        "mappings": {}
    }

def create_csv_template(output_file="template.csv"):
    """–°—Ç–≤–æ—Ä—é—î CSV —à–∞–±–ª–æ–Ω –¥–ª—è –∑–∞–ø–æ–≤–Ω–µ–Ω–Ω—è"""

    template_data = {
        "–®–∏—Ñ—Ä": ["–ó–û 01", "–ó–û 02", "–ü–û 01", "–ü–û 02"],
        "–ù–∞–∑–≤–∞ –¥–∏—Å—Ü–∏–ø–ª—ñ–Ω–∏": [
            "–ú–∞—Ç–µ–º–∞—Ç–∏—á–Ω–∏–π –∞–Ω–∞–ª—ñ–∑",
            "–ê–ª–≥–µ–±—Ä–∞ —Ç–∞ –≥–µ–æ–º–µ—Ç—Ä—ñ—è",
            "–ü—Ä–æ–≥—Ä–∞–º—É–≤–∞–Ω–Ω—è",
            "–ö–æ–º–ø'—é—Ç–µ—Ä–Ω–∞ –≥—Ä–∞—Ñ—ñ–∫–∞"
        ],
        "–ö–æ–º–ø–µ—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—ñ": [
            "–ó–ö 1, –ó–ö 2, –§–ö 6, –§–ö 7",
            "–ó–ö 1, –ó–ö 2, –§–ö 7",
            "–ó–ö 1, –ó–ö 5, –§–ö 5, –§–ö 10",
            "–ó–ö 5, –§–ö 5, –§–ö 10"
        ],
        "–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –Ω–∞–≤—á–∞–Ω–Ω—è": [
            "–ü–†–ù 1, –ü–†–ù 2",
            "–ü–†–ù 2",
            "–ü–†–ù 4, –ü–†–ù 16",
            "–ü–†–ù 15, –ü–†–ù 16"
        ]
    }

    df = pd.DataFrame(template_data)
    df.to_csv(output_file, index=False, encoding='utf-8')

    print(f"üìÑ CSV —à–∞–±–ª–æ–Ω —Å—Ç–≤–æ—Ä–µ–Ω–æ: {output_file}")
    print("üí° –ó–∞–ø–æ–≤–Ω—ñ—Ç—å –π–æ–≥–æ —Ç–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–π—Ç–µ –¥–ª—è –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—ó —É YAML")

def validate_csv_before_conversion(csv_file):
    """–ü–µ—Ä–µ–≤—ñ—Ä—è—î CSV —Ñ–∞–π–ª –ø–µ—Ä–µ–¥ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—î—é"""
    try:
        df = pd.read_csv(csv_file, encoding='utf-8')

        print(f"üìã –ê–Ω–∞–ª—ñ–∑ CSV —Ñ–∞–π–ª—É: {csv_file}")
        print(f"üìä –†—è–¥–∫—ñ–≤: {len(df)}")
        print(f"üìä –ö–æ–ª–æ–Ω–æ–∫: {len(df.columns)}")
        print("\nüìù –ö–æ–ª–æ–Ω–∫–∏:")
        for i, col in enumerate(df.columns):
            print(f"  {i+1}. {col}")

        print("\nüìñ –ü–µ—Ä—à—ñ 3 —Ä—è–¥–∫–∏:")
        print(df.head(3).to_string())

        # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –Ω–∞ –ø–æ—Ä–æ–∂–Ω—ñ –∫–ª—ñ—Ç–∏–Ω–∫–∏
        empty_cells = df.isnull().sum()
        if empty_cells.any():
            print("\n‚ö†Ô∏è –ü–æ—Ä–æ–∂–Ω—ñ –∫–ª—ñ—Ç–∏–Ω–∫–∏:")
            for col, count in empty_cells.items():
                if count > 0:
                    print(f"  {col}: {count} –ø–æ—Ä–æ–∂–Ω—ñ—Ö")

        return True

    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ —á–∏—Ç–∞–Ω–Ω—è CSV: {e}")
        return False

